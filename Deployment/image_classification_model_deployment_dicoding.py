# -*- coding: utf-8 -*-
"""Image Classification Model Deployment Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/192dn1Z1AvSd5478sDuWEsH72m6e1Ja7k

# **Mammals Image Classification**
Nama    : Muhammad Shadeq <br>
Email   : muhammadshadeq25@gmail.com <br>
Dataset : https://www.kaggle.com/datasets/asaniczka/mammals-image-classification-dataset-45-animals

**Import library**
"""

import pandas as pd
import numpy as np
import zipfile
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications.densenet import DenseNet201,preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten,Conv2D,MaxPooling2D,Dense,Lambda
from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tensorflow.keras.utils import get_file

from google.colab import drive
from google.colab import files
import pathlib

! pip install -q tf-nightly

"""**API Kaggle dan Download Dataset**"""

! pip install kaggle

drive.mount('/content/gdrive')

os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

!kaggle datasets download -d asaniczka/mammals-image-classification-dataset-45-animals

"""**Lakukan Ekstrak File zip**"""

local_zip = '/content/mammals-image-classification-dataset-45-animals.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/')
zip_ref.close()

"""**Data Directories**"""

img_dir = '/content/mammals'
test_dir = '/content/test/test'

"""**image size and batch size**"""

image_size = 256
batch_size = 30

"""**Training data**"""

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=img_dir,
    validation_split=0.2,
    subset="training",
    seed=1000,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical'
)

class_names=train_ds.class_names
class_names

"""**Validation data**"""

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=img_dir,
    validation_split=0.2,
    subset="validation",
    seed=1000,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical'
)

"""**Test data**"""

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory=test_dir,
    image_size=(image_size,image_size),
    batch_size=batch_size,
    label_mode='categorical',
)

"""**Visualisasikan (plot) beberapa gambar dari data pelatihan dengan labelnya**"""

# x_shape = []
# y_shape = []
plt.figure(figsize=(12,15))
for img,label in train_ds.take(1):
    for i in range(25):
#         x_shape.append(img[i].shape[0])
#         y_shape.append(img[i].shape[1])
        ax = plt.subplot(5,5,i+1)
        plt.imshow(img[i].numpy().astype("uint8"))
        plt.title(class_names[np.argmax(label[i])])

"""**Model**"""

base_model = DenseNet201(weights = 'imagenet',
                        include_top = False,
                        input_shape=(image_size,image_size,3))
base_model.trainable = False

model = Sequential()
model.add(Lambda(preprocess_input,input_shape = (image_size,image_size,3)))
model.add(base_model)
model.add(Conv2D(32, 3, padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(64, 3, padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(64,activation = 'relu'))
model.add(Dense(32,activation = 'relu'))
model.add(Dense(45,activation = 'softmax'))

model.compile(optimizer='adam',loss = 'CategoricalCrossentropy',metrics=['accuracy'])
model.summary()

class stop(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.98 and logs.get('val_accuracy')>0.88):
      self.model.stop_training=True
      print("\n Akurasi telah mencapai > 98%!")
callbacks=stop()

epochs = 45
history = model.fit(train_ds,validation_data=val_ds,epochs = epochs , batch_size=30,callbacks=[callbacks])

"""**Plot accuracy dan error (train dan validation)**"""

history = pd.DataFrame(model.history.history)
history.plot()

"""**Menyimpan model**"""

# Menyimpan model dalam format SavedModel
export_dir = '/gdrive/My Drive/Kaggle/saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)

"""**Testing foto mammals random dari folder test**"""

prediction = np.argmax(model.predict(test_ds), axis=-1)
prediction

predictions = []
for i in prediction:
    predictions.append(class_names[i])

plt.figure(figsize=(12,15))
for image,label  in test_ds.take(1):
        for i in range(11):
            plt.subplot(4,3,i+1)
            plt.imshow(image[i].numpy().astype("uint8"))
            plt.title(predictions[i])