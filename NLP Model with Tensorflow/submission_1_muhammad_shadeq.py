# -*- coding: utf-8 -*-
"""Submission_1 - Muhammad Shadeq.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vGqMM8lUsaRSPL31_5xw0LOxXECYXttE

# **Membuat Model NLP dengan TensorFlow**

Nama    : Muhammad Shadeq <br />
Dataset : https://www.kaggle.com/datasets/ananthu017/question-classification
"""

import numpy as np
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import accuracy_score
import tensorflow as tf
import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

rd = pd.read_csv("Question_Classification_Dataset.csv")

rd = rd.drop(columns=['Unnamed: 0', 'Category1', 'Category2'])

rd.head()

rd = rd.drop(rd[rd['Category0'] == 'ENTITY'].index)

rd = rd.drop(rd[rd['Category0'] == 'ABBREVIATION'].index)

model_category = pd.get_dummies(rd.Category0)
new_ds         = pd.concat([rd,model_category], axis=1)
new_ds         = new_ds.drop(columns='Category0')
new_ds

X_column  = new_ds['Questions'].astype(str)
Y_column  = new_ds[['DESCRIPTION','LOCATION','HUMAN','NUMERIC']]

X_latih, X_uji, y_latih, y_uji = train_test_split(X_column,Y_column,test_size=0.2)

"""### **Tokenizer**"""

getTokenizer = Tokenizer(num_words=5000, oov_token='x')
getTokenizer.fit_on_texts(X_latih)
getTokenizer.fit_on_texts(X_uji)

A_latih      = getTokenizer.texts_to_sequences(X_latih)
A_uji        = getTokenizer.texts_to_sequences(X_uji)

B_latih      = pad_sequences(A_latih)
B_uji        = pad_sequences(A_uji)

model_ = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.75),
    tf.keras.layers.Dense(64,activation='relu'),
    tf.keras.layers.Dropout(0.75),
    tf.keras.layers.Dense(4,activation='softmax')
])


model_.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs={}):
    if(logs.get('val_accuracy') > 0.9):
      print("\n Akurasi lebih dari 90%")
      self.model.stop_training = True

callbacks = myCallback()

num_of_epochs = 30

history_ = model_.fit(B_latih, y_latih, epochs=num_of_epochs, callbacks=[callbacks], validation_data=(B_uji, y_uji), verbose=2)

import matplotlib.pyplot as plt
plt.plot(history_.history['accuracy'])
plt.plot(history_.history['val_accuracy'])
plt.title('Model Akurasi')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

plt.plot(history_.history['loss'])
plt.plot(history_.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()